# ğŸ§ âš¡ NeuraVis

### NeuraVis is a neural visualization engine that turns ideas into motion.



- This engine converts plain-language prompts into Manim animations using an **LLM-driven code generation pipeline**, then executes Manim to render MP4 videos and persists metadata and assets to cloud storage.


-----



### ğŸ§© Working architecture (compact)

```

Text Prompt
     â†“
LLM Reasoning
     â†“
Scene Planning
     â†“
Manim Code Generation
     â†“
Render Pipeline
     â†“
Encoded Video Output

```


-------


### âš™ Pipeline

Prompt â†’ Semantic parse â†’ Scene plan â†’ Manim.py â†’ Headless render â†’ FFmpeg â†’ MP4 â†’ (store â†’ deliver)



--------


### ğŸ”§ Core tech 

**LLM orchestration**: LangChain patterns + OpenAI / Google GenAI adapters

**Animation**: Manim (programmatic scenes) + FFmpeg (encode)

**API / Orchestration**: FastAPI (Python)

**Persistence** : Supabase (Postgres + Storage)

**UI**: Next.js (React, TypeScript, CSS)

**Containerization** : Docker



-----



### ğŸ“‚ Repo layout (short)

```

NeuraVis/
â”œâ”€ Backend/         # FastAPI, Model layer (LLM â†’ code), auth, DB config
â”‚  â”œâ”€ Model/        # promptâ†’planâ†’code synthesis
â”‚  â”œâ”€ auth/         # JWT & auth routes
â”‚  â”œâ”€ main.py
â”‚  â””â”€ requirements.txt
â”œâ”€ frontend/        # Next.js UI (prompt, preview, auth)
â”œâ”€ animations/      # generated .py scene artifacts
â”œâ”€ media/           # rendered MP4s
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â””â”€ .env.example

```


----




### â–¶ï¸ Quick start â€” local (dev)



#### Backend

```
cd Backend
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
python main.py         
```

#### Frontend (dev)

```
cd ../frontend
npm install
npm run dev
```



### â–¶ï¸ Quick start â€” Docker

```
# from repo root
docker compose up --build
# Backend exposed on :8000 by default
```


-----


### âœ… Minimal smoke test

Start services.

``` GET http://localhost:8000/health (or root). ```

POST a tiny prompt to the generate endpoint â†’ confirm .py in animations/ and .mp4 in media/.


----- 


### ğŸš€ Future Roadmap

- TTS / voiceover per scene (synchronized)

- Preset visual styles (whiteboard, cinematic, sketch)

- Low-res realtime preview for iteration speed

- GPU render pool for scale (optional CUDA workers)

